version: "3.9"

services:
  nexus:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: nexus
    ports:
      - "${PORT:-8080}:8080"
    environment:
      - HOST=0.0.0.0
      - PORT=8080
      - ADMIN_API_KEY=${ADMIN_API_KEY:-change-me-to-a-random-secret}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
      - COMPLEXITY_THRESHOLD=${COMPLEXITY_THRESHOLD:-60}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost:8080}
      - GITHUB_TOKEN=${GITHUB_TOKEN:-}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN:-}
      - TELEGRAM_ALLOWED_USERS=${TELEGRAM_ALLOWED_USERS:-}
    volumes:
      - nexus-data:/app/data
      - ./docs:/app/docs:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8080/api/status')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # Optional: Ollama for local model inference
  ollama:
    image: ollama/ollama:latest
    container_name: nexus-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama
    restart: unless-stopped
    profiles:
      - with-ollama

volumes:
  nexus-data:
    driver: local
  ollama-models:
    driver: local
